{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba859c2",
   "metadata": {},
   "source": [
    "# University Admission Prediction (Binary Classification)\n",
    "\n",
    "This notebook loads the provided dataset (`data/dataset.csv`), prepares a binary target, trains a simple model, and prints basic dataset information and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset (kept in repo at: data/dataset.csv)\n",
    "df = pd.read_csv('data/dataset.csv')\n",
    "\n",
    "# Clean column names (remove extra spaces)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print('Shape:', df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target\n",
    "# Original dataset has a probability-like column: 'Chance of Admit'\n",
    "# Convert it into binary label:\n",
    "#   1 = Admitted (>= threshold)\n",
    "#   0 = Not Admitted (< threshold)\n",
    "\n",
    "THRESHOLD = 0.75\n",
    "\n",
    "df['Admitted'] = (df['Chance of Admit'] >= THRESHOLD).astype(int)\n",
    "\n",
    "# Drop non-feature columns\n",
    "X = df.drop(columns=['Admitted', 'Chance of Admit'])\n",
    "\n",
    "# If Serial No exists, drop it (identifier)\n",
    "if 'Serial No.' in X.columns:\n",
    "    X = X.drop(columns=['Serial No.'])\n",
    "\n",
    "y = df['Admitted']\n",
    "\n",
    "X.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_test, pred))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
